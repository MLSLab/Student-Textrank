{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextRank \n",
    "## 핵심단어/문장 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 핵심 문장 구하기\n",
    "\n",
    "2-1. 파일 읽기 <br>\n",
    "2-2. 단어 tokenize 후, 단어 index 만들기<br>\n",
    "2-3. 문장 그래프를 만들기<br>\n",
    "2-4. 문장 그래프을 pagerank에 적용하기<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import Counter\n",
    "from konlpy.tag import Kkma\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test1.txt', encoding='utf-8') as f:\n",
    "    sents = [sent for row in f for sent in row.strip().split(\". \") if len(sent) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['인공신경망(artificial neural network, ANN)은 기계학습과 인지과학에서 생물학의 신경망에서 영감을 얻은 통계학적 학습 알고리즘으로 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 가리킨다',\n",
       " '인공신경망에는 교사 신호(정답)의 입력에 의해서 문제에 최적화되어 가는 교사 학습과 교사 신호를 필요로 하지 않는 비교사 학습이 있다',\n",
       " '명확한 해답이 있는 경우에는 교사 학습이, 데이터 클러스터링에는 비교사 학습이 이용된다',\n",
       " '다른 기계학습과 같이 신경망은 일반적으로 규칙기반 프로그래밍으로 풀기 어려운 컴퓨터 비전 또는 음성 인식과 같은 다양한 범위의 문제를 푸는데 이용된다.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. 단어 tokenize 후, 단어 index 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()\n",
    "def kkma_tokenize(sent):\n",
    "    words = kkma.pos(sent)\n",
    "    return [word for word, pos in words \n",
    "             if ( 'NN' in pos or '/VA' in pos or '/VV' in pos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'학습': 8, '교사': 6, '신경망': 4, '인공': 3, '문제': 3, '기계': 2, '시냅스': 2, '결합': 2, '신호': 2, '비': 2, '이용': 2, '은': 1, '인지': 1, '과학': 1, '생물학': 1, '영감': 1, '통계': 1, '학적': 1, '알고리즘': 1, '네트워크': 1, '형성': 1, '뉴런': 1, '노드': 1, '이': 1, '세기': 1, '변화': 1, '해결': 1, '능력': 1, '모델': 1, '전반': 1, '정답': 1, '의': 1, '입력': 1, '필요': 1, '해답': 1, '경우': 1, '데이터': 1, '러': 1, '스터링': 1, '일반적': 1, '규칙': 1, '기반': 1, '프로그래밍': 1, '컴퓨터': 1, '비전': 1, '음성': 1, '인식': 1, '다양': 1, '범위': 1})\n"
     ]
    }
   ],
   "source": [
    "word_counter = Counter(w for sent in sents for w in kkma_tokenize(sent))\n",
    "print(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'인공': 3, '신경망': 4, '기계': 2, '학습': 8, '시냅스': 2, '결합': 2, '문제': 3, '교사': 6, '신호': 2, '비': 2, '이용': 2}\n"
     ]
    }
   ],
   "source": [
    "min_count=2 # Minumum term frequency\n",
    "min_word_counter = {w:c for w,c in word_counter.items() if c >= min_count}\n",
    "print(min_word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정렬 확인 >>  [('학습', 8), ('교사', 6), ('신경망', 4), ('인공', 3), ('문제', 3), ('기계', 2), ('시냅스', 2), ('결합', 2), ('신호', 2), ('비', 2), ('이용', 2)]\n",
      "\n",
      "정렬을 기준으로 단어 list 생성 >>  ['학습', '교사', '신경망', '인공', '문제', '기계', '시냅스', '결합', '신호', '비', '이용']\n"
     ]
    }
   ],
   "source": [
    "## idx_to_vocab -> data type : list\n",
    "## Word list corresponding row and column\n",
    "idx_to_vocab = [w for w, _ in sorted(min_word_counter.items(), key=lambda x:-x[1])] \n",
    "print(\"정렬 확인 >> \", sorted(min_word_counter.items(), key=lambda x:-x[1])) # 1번째 요소로 내림차순(-) 정렬\n",
    "print()\n",
    "print(\"정렬을 기준으로 단어 list 생성 >> \", idx_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도 순으로 정렬한 list에 번호를 매겨 index 생성\n",
      " {'학습': 0, '교사': 1, '신경망': 2, '인공': 3, '문제': 4, '기계': 5, '시냅스': 6, '결합': 7, '신호': 8, '비': 9, '이용': 10}\n"
     ]
    }
   ],
   "source": [
    "## vocab_to_idx -> data type : dict\n",
    "## Vocabulary to index mapper\n",
    "vocab_to_idx = {vocab:idx for idx, vocab in enumerate(idx_to_vocab)}\n",
    "print(\"빈도 순으로 정렬한 list에 번호를 매겨 index 생성\\n\", vocab_to_idx)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3. 문장 그래프를 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최소 출현 빈도를 넘은 단어들을 이용해 문장 간 similarity를 구한다.<br>\n",
    "문장 간 similarity가 0.3 보다 작은 경우에는 edge를 연결하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_graph(sents, similarity, min_count=2, min_sim=0.3):\n",
    "#     _, vocab_to_idx = scan_vocabulary(sents, tokenize, min_count)\n",
    "\n",
    "    tokens = [[w for w in kkma_tokenize(sent) if w in vocab_to_idx] for sent in sents]\n",
    "#     tokens = [[w for w in tokenize(sent) if w in vocab_to_idx] for sent in sents]\n",
    "    rows, cols, data = [], [], []\n",
    "    n_sents = len(tokens)\n",
    "    for i, tokens_i in enumerate(tokens):\n",
    "        for j, tokens_j in enumerate(tokens):\n",
    "#             if i >= j:\n",
    "#                 continue\n",
    "            sim = similarity(tokens_i, tokens_j)\n",
    "            print(\"\\nS1-S2 similarity = \", sim)\n",
    "            print(\"-\"*100)\n",
    "            \n",
    "            if sim < min_sim:\n",
    "                continue\n",
    "            rows.append(i)\n",
    "            cols.append(j)\n",
    "            data.append(sim)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(n_sents, n_sents))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cosine similarity 를 사용한 similarity 구하는 방법<br>\n",
    "짧은 문장에 민감하게 반응한다. <br>\n",
    "문장에 쓰인 단어가 적은데 비해 동시에 등장한 단어가 여러개라면 유사도가 높게 나올 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$cos(\\theta)=\\frac{{A}\\cdot{B}}{\\|A\\|\\|B\\|}=\\frac{\\Sigma^{n}_{i=1}{(A_{i})*(B_{i})}}{\\sqrt{\\Sigma^{n}_{i=1}{(A_{i})^2}}*\\sqrt{\\Sigma^{n}_{i=1}{(B_{i})^2}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sent_sim(s1, s2):\n",
    "    if (not s1) or (not s2):\n",
    "        return 0\n",
    "    \n",
    "    print(\"[s1]\", s1)\n",
    "    print(\"[s2]\", s2, \"\\n\")\n",
    "    \n",
    "    s1 = Counter(s1)\n",
    "    s2 = Counter(s2)\n",
    "    \n",
    "    print(\"[s1_counter]\", s1)\n",
    "    print(\"[s2_counter]\", s2, \"\\n\")\n",
    "    \n",
    "    norm1 = math.sqrt(sum(v ** 2 for v in s1.values()))\n",
    "    norm2 = math.sqrt(sum(v ** 2 for v in s2.values()))\n",
    "    prod = 0\n",
    "    for k, v in s1.items():\n",
    "        prod += v * s2.get(k, 0)\n",
    "        print(\"[s1_word] %3s \\t[s1_word_count]%2d \\t[s2.get(s1_word)] %2d \\t[prod] %3d\"%( k, v, s2.get(k, 0), prod))\n",
    "\n",
    "    return prod / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s1] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "[s2] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제'] \n",
      "\n",
      "[s1_counter] Counter({'학습': 3, '인공': 2, '신경망': 2, '시냅스': 2, '결합': 2, '기계': 1, '문제': 1})\n",
      "[s2_counter] Counter({'학습': 3, '인공': 2, '신경망': 2, '시냅스': 2, '결합': 2, '기계': 1, '문제': 1}) \n",
      "\n",
      "[s1_word]  인공 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]   4\n",
      "[s1_word] 신경망 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]   8\n",
      "[s1_word]  기계 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   9\n",
      "[s1_word]  학습 \t[s1_word_count] 3 \t[s2.get(s1_word)]  3 \t[prod]  18\n",
      "[s1_word] 시냅스 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]  22\n",
      "[s1_word]  결합 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]  26\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]  27\n",
      "\n",
      "S1-S2 similarity =  1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "[s2] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습'] \n",
      "\n",
      "[s1_counter] Counter({'학습': 3, '인공': 2, '신경망': 2, '시냅스': 2, '결합': 2, '기계': 1, '문제': 1})\n",
      "[s2_counter] Counter({'교사': 4, '신호': 2, '학습': 2, '인공': 1, '신경망': 1, '문제': 1, '비': 1}) \n",
      "\n",
      "[s1_word]  인공 \t[s1_word_count] 2 \t[s2.get(s1_word)]  1 \t[prod]   2\n",
      "[s1_word] 신경망 \t[s1_word_count] 2 \t[s2.get(s1_word)]  1 \t[prod]   4\n",
      "[s1_word]  기계 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   4\n",
      "[s1_word]  학습 \t[s1_word_count] 3 \t[s2.get(s1_word)]  2 \t[prod]  10\n",
      "[s1_word] 시냅스 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]  10\n",
      "[s1_word]  결합 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]  10\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]  11\n",
      "\n",
      "S1-S2 similarity =  0.40006613209931935\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "[s2] ['교사', '학습', '비', '교사', '학습', '이용'] \n",
      "\n",
      "[s1_counter] Counter({'학습': 3, '인공': 2, '신경망': 2, '시냅스': 2, '결합': 2, '기계': 1, '문제': 1})\n",
      "[s2_counter] Counter({'교사': 2, '학습': 2, '비': 1, '이용': 1}) \n",
      "\n",
      "[s1_word]  인공 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word] 신경망 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word]  기계 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word]  학습 \t[s1_word_count] 3 \t[s2.get(s1_word)]  2 \t[prod]   6\n",
      "[s1_word] 시냅스 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   6\n",
      "[s1_word]  결합 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   6\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   6\n",
      "\n",
      "S1-S2 similarity =  0.36514837167011066\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "[s2] ['기계', '학습', '신경망', '문제', '이용'] \n",
      "\n",
      "[s1_counter] Counter({'학습': 3, '인공': 2, '신경망': 2, '시냅스': 2, '결합': 2, '기계': 1, '문제': 1})\n",
      "[s2_counter] Counter({'기계': 1, '학습': 1, '신경망': 1, '문제': 1, '이용': 1}) \n",
      "\n",
      "[s1_word]  인공 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word] 신경망 \t[s1_word_count] 2 \t[s2.get(s1_word)]  1 \t[prod]   2\n",
      "[s1_word]  기계 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   3\n",
      "[s1_word]  학습 \t[s1_word_count] 3 \t[s2.get(s1_word)]  1 \t[prod]   6\n",
      "[s1_word] 시냅스 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   6\n",
      "[s1_word]  결합 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   6\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   7\n",
      "\n",
      "S1-S2 similarity =  0.6024640760767093\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "[s2] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제'] \n",
      "\n",
      "[s1_counter] Counter({'교사': 4, '신호': 2, '학습': 2, '인공': 1, '신경망': 1, '문제': 1, '비': 1})\n",
      "[s2_counter] Counter({'학습': 3, '인공': 2, '신경망': 2, '시냅스': 2, '결합': 2, '기계': 1, '문제': 1}) \n",
      "\n",
      "[s1_word]  인공 \t[s1_word_count] 1 \t[s2.get(s1_word)]  2 \t[prod]   2\n",
      "[s1_word] 신경망 \t[s1_word_count] 1 \t[s2.get(s1_word)]  2 \t[prod]   4\n",
      "[s1_word]  교사 \t[s1_word_count] 4 \t[s2.get(s1_word)]  0 \t[prod]   4\n",
      "[s1_word]  신호 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   4\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   5\n",
      "[s1_word]  학습 \t[s1_word_count] 2 \t[s2.get(s1_word)]  3 \t[prod]  11\n",
      "[s1_word]   비 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]  11\n",
      "\n",
      "S1-S2 similarity =  0.40006613209931935\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "[s2] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습'] \n",
      "\n",
      "[s1_counter] Counter({'교사': 4, '신호': 2, '학습': 2, '인공': 1, '신경망': 1, '문제': 1, '비': 1})\n",
      "[s2_counter] Counter({'교사': 4, '신호': 2, '학습': 2, '인공': 1, '신경망': 1, '문제': 1, '비': 1}) \n",
      "\n",
      "[s1_word]  인공 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   1\n",
      "[s1_word] 신경망 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   2\n",
      "[s1_word]  교사 \t[s1_word_count] 4 \t[s2.get(s1_word)]  4 \t[prod]  18\n",
      "[s1_word]  신호 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]  22\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]  23\n",
      "[s1_word]  학습 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]  27\n",
      "[s1_word]   비 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]  28\n",
      "\n",
      "S1-S2 similarity =  0.9999999999999999\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "[s2] ['교사', '학습', '비', '교사', '학습', '이용'] \n",
      "\n",
      "[s1_counter] Counter({'교사': 4, '신호': 2, '학습': 2, '인공': 1, '신경망': 1, '문제': 1, '비': 1})\n",
      "[s2_counter] Counter({'교사': 2, '학습': 2, '비': 1, '이용': 1}) \n",
      "\n",
      "[s1_word]  인공 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word] 신경망 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word]  교사 \t[s1_word_count] 4 \t[s2.get(s1_word)]  2 \t[prod]   8\n",
      "[s1_word]  신호 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   8\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   8\n",
      "[s1_word]  학습 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]  12\n",
      "[s1_word]   비 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]  13\n",
      "\n",
      "S1-S2 similarity =  0.7768985960673559\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "[s2] ['기계', '학습', '신경망', '문제', '이용'] \n",
      "\n",
      "[s1_counter] Counter({'교사': 4, '신호': 2, '학습': 2, '인공': 1, '신경망': 1, '문제': 1, '비': 1})\n",
      "[s2_counter] Counter({'기계': 1, '학습': 1, '신경망': 1, '문제': 1, '이용': 1}) \n",
      "\n",
      "[s1_word]  인공 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word] 신경망 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   1\n",
      "[s1_word]  교사 \t[s1_word_count] 4 \t[s2.get(s1_word)]  0 \t[prod]   1\n",
      "[s1_word]  신호 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   1\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   2\n",
      "[s1_word]  학습 \t[s1_word_count] 2 \t[s2.get(s1_word)]  1 \t[prod]   4\n",
      "[s1_word]   비 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   4\n",
      "\n",
      "S1-S2 similarity =  0.33806170189140655\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "[s2] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제'] \n",
      "\n",
      "[s1_counter] Counter({'교사': 2, '학습': 2, '비': 1, '이용': 1})\n",
      "[s2_counter] Counter({'학습': 3, '인공': 2, '신경망': 2, '시냅스': 2, '결합': 2, '기계': 1, '문제': 1}) \n",
      "\n",
      "[s1_word]  교사 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word]  학습 \t[s1_word_count] 2 \t[s2.get(s1_word)]  3 \t[prod]   6\n",
      "[s1_word]   비 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   6\n",
      "[s1_word]  이용 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   6\n",
      "\n",
      "S1-S2 similarity =  0.36514837167011066\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "[s2] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습'] \n",
      "\n",
      "[s1_counter] Counter({'교사': 2, '학습': 2, '비': 1, '이용': 1})\n",
      "[s2_counter] Counter({'교사': 4, '신호': 2, '학습': 2, '인공': 1, '신경망': 1, '문제': 1, '비': 1}) \n",
      "\n",
      "[s1_word]  교사 \t[s1_word_count] 2 \t[s2.get(s1_word)]  4 \t[prod]   8\n",
      "[s1_word]  학습 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]  12\n",
      "[s1_word]   비 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]  13\n",
      "[s1_word]  이용 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]  13\n",
      "\n",
      "S1-S2 similarity =  0.7768985960673559\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "[s2] ['교사', '학습', '비', '교사', '학습', '이용'] \n",
      "\n",
      "[s1_counter] Counter({'교사': 2, '학습': 2, '비': 1, '이용': 1})\n",
      "[s2_counter] Counter({'교사': 2, '학습': 2, '비': 1, '이용': 1}) \n",
      "\n",
      "[s1_word]  교사 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]   4\n",
      "[s1_word]  학습 \t[s1_word_count] 2 \t[s2.get(s1_word)]  2 \t[prod]   8\n",
      "[s1_word]   비 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   9\n",
      "[s1_word]  이용 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]  10\n",
      "\n",
      "S1-S2 similarity =  0.9999999999999998\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "[s2] ['기계', '학습', '신경망', '문제', '이용'] \n",
      "\n",
      "[s1_counter] Counter({'교사': 2, '학습': 2, '비': 1, '이용': 1})\n",
      "[s2_counter] Counter({'기계': 1, '학습': 1, '신경망': 1, '문제': 1, '이용': 1}) \n",
      "\n",
      "[s1_word]  교사 \t[s1_word_count] 2 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word]  학습 \t[s1_word_count] 2 \t[s2.get(s1_word)]  1 \t[prod]   2\n",
      "[s1_word]   비 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   2\n",
      "[s1_word]  이용 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   3\n",
      "\n",
      "S1-S2 similarity =  0.42426406871192845\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['기계', '학습', '신경망', '문제', '이용']\n",
      "[s2] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제'] \n",
      "\n",
      "[s1_counter] Counter({'기계': 1, '학습': 1, '신경망': 1, '문제': 1, '이용': 1})\n",
      "[s2_counter] Counter({'학습': 3, '인공': 2, '신경망': 2, '시냅스': 2, '결합': 2, '기계': 1, '문제': 1}) \n",
      "\n",
      "[s1_word]  기계 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   1\n",
      "[s1_word]  학습 \t[s1_word_count] 1 \t[s2.get(s1_word)]  3 \t[prod]   4\n",
      "[s1_word] 신경망 \t[s1_word_count] 1 \t[s2.get(s1_word)]  2 \t[prod]   6\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   7\n",
      "[s1_word]  이용 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   7\n",
      "\n",
      "S1-S2 similarity =  0.6024640760767093\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['기계', '학습', '신경망', '문제', '이용']\n",
      "[s2] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습'] \n",
      "\n",
      "[s1_counter] Counter({'기계': 1, '학습': 1, '신경망': 1, '문제': 1, '이용': 1})\n",
      "[s2_counter] Counter({'교사': 4, '신호': 2, '학습': 2, '인공': 1, '신경망': 1, '문제': 1, '비': 1}) \n",
      "\n",
      "[s1_word]  기계 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word]  학습 \t[s1_word_count] 1 \t[s2.get(s1_word)]  2 \t[prod]   2\n",
      "[s1_word] 신경망 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   3\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   4\n",
      "[s1_word]  이용 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   4\n",
      "\n",
      "S1-S2 similarity =  0.33806170189140655\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['기계', '학습', '신경망', '문제', '이용']\n",
      "[s2] ['교사', '학습', '비', '교사', '학습', '이용'] \n",
      "\n",
      "[s1_counter] Counter({'기계': 1, '학습': 1, '신경망': 1, '문제': 1, '이용': 1})\n",
      "[s2_counter] Counter({'교사': 2, '학습': 2, '비': 1, '이용': 1}) \n",
      "\n",
      "[s1_word]  기계 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   0\n",
      "[s1_word]  학습 \t[s1_word_count] 1 \t[s2.get(s1_word)]  2 \t[prod]   2\n",
      "[s1_word] 신경망 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   2\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  0 \t[prod]   2\n",
      "[s1_word]  이용 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   3\n",
      "\n",
      "S1-S2 similarity =  0.42426406871192845\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[s1] ['기계', '학습', '신경망', '문제', '이용']\n",
      "[s2] ['기계', '학습', '신경망', '문제', '이용'] \n",
      "\n",
      "[s1_counter] Counter({'기계': 1, '학습': 1, '신경망': 1, '문제': 1, '이용': 1})\n",
      "[s2_counter] Counter({'기계': 1, '학습': 1, '신경망': 1, '문제': 1, '이용': 1}) \n",
      "\n",
      "[s1_word]  기계 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   1\n",
      "[s1_word]  학습 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   2\n",
      "[s1_word] 신경망 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   3\n",
      "[s1_word]  문제 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   4\n",
      "[s1_word]  이용 \t[s1_word_count] 1 \t[s2.get(s1_word)]  1 \t[prod]   5\n",
      "\n",
      "S1-S2 similarity =  0.9999999999999998\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sent_cosine_graph = sent_graph(sents, cosine_sent_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40006613 0.36514837 0.60246408]\n",
      " [0.40006613 1.         0.7768986  0.3380617 ]\n",
      " [0.36514837 0.7768986  1.         0.42426407]\n",
      " [0.60246408 0.3380617  0.42426407 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(sent_cosine_graph.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TextRank 에서 제안한 similarity 구하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 문장의 단어 수와 공통으로 등장하는 단어 수를 고려한다.<br>\n",
    "cosine similarity와 달리 최대 값이 1이 아니고, 문장의 길이가 길수록 높은 유사도를 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$sim(s_{1}, s_{2}) = \\frac{|{w_{k}}|{w_{k}}\\in{S_{1}} \\& {w_{k}}\\in{S_{2}} |}{\\log{|S_{1}|}+\\log{|S_{2}|}}$\n",
    "\n",
    "$𝑆_1$ 문장 1의 단어 수<br>\n",
    "$𝑆_2$ 문장 2의 단어 수<br>\n",
    "$|{w_{k}}|{w_{k}}\\in{S_{1}} \\& {w_{k}}\\in{S_{2}}|$ 문장 1과 2에 공통으로 등장한 단어 수<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_sent_sim(s1, s2):\n",
    "    \n",
    "    print(\"\\n[s1]\", s1)\n",
    "    print(\"[s2]\", s2)\n",
    "    \n",
    "    n1 = len(s1)\n",
    "    n2 = len(s2)\n",
    "    if (n1 <= 1) or (n2 <= 1):\n",
    "        print(\"???\")\n",
    "        return 0\n",
    "    \n",
    "    common = len(set(s1).intersection(set(s2)))\n",
    "    base = math.log(n1) + math.log(n2)\n",
    "    \n",
    "    print(\"\\nS1,S2 교집합 {} --> {}\".format(set(s1).intersection(set(s2)), common))\n",
    "    \n",
    "    return common / base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[s1] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "[s2] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "\n",
      "S1,S2 교집합 {'문제', '신경망', '인공', '결합', '학습', '기계', '시냅스'} --> 7\n",
      "\n",
      "S1-S2 similarity =  1.36454935837948\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "[s2] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "\n",
      "S1,S2 교집합 {'인공', '문제', '학습', '신경망'} --> 4\n",
      "\n",
      "S1-S2 similarity =  0.7921017934486901\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "[s2] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "\n",
      "S1,S2 교집합 {'학습'} --> 1\n",
      "\n",
      "S1-S2 similarity =  0.22953106112437666\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "[s2] ['기계', '학습', '신경망', '문제', '이용']\n",
      "\n",
      "S1,S2 교집합 {'학습', '문제', '기계', '신경망'} --> 4\n",
      "\n",
      "S1-S2 similarity =  0.9582244629880743\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "[s2] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "\n",
      "S1,S2 교집합 {'인공', '문제', '학습', '신경망'} --> 4\n",
      "\n",
      "S1-S2 similarity =  0.7921017934486901\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "[s2] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "\n",
      "S1,S2 교집합 {'비', '문제', '신경망', '인공', '교사', '신호', '학습'} --> 7\n",
      "\n",
      "S1-S2 similarity =  1.4085036153364563\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "[s2] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "\n",
      "S1,S2 교집합 {'비', '교사', '학습'} --> 3\n",
      "\n",
      "S1-S2 similarity =  0.7014809939594299\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "[s2] ['기계', '학습', '신경망', '문제', '이용']\n",
      "\n",
      "S1,S2 교집합 {'문제', '학습', '신경망'} --> 3\n",
      "\n",
      "S1-S2 similarity =  0.7327180100279169\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "[s2] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "\n",
      "S1,S2 교집합 {'학습'} --> 1\n",
      "\n",
      "S1-S2 similarity =  0.22953106112437666\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "[s2] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "\n",
      "S1,S2 교집합 {'비', '교사', '학습'} --> 3\n",
      "\n",
      "S1-S2 similarity =  0.7014809939594299\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "[s2] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "\n",
      "S1,S2 교집합 {'이용', '비', '학습', '교사'} --> 4\n",
      "\n",
      "S1-S2 similarity =  1.1162212531024944\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "[s2] ['기계', '학습', '신경망', '문제', '이용']\n",
      "\n",
      "S1,S2 교집합 {'이용', '학습'} --> 2\n",
      "\n",
      "S1-S2 similarity =  0.5880282075904122\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['기계', '학습', '신경망', '문제', '이용']\n",
      "[s2] ['인공', '신경망', '기계', '학습', '신경망', '학습', '시냅스', '결합', '인공', '학습', '시냅스', '결합', '문제']\n",
      "\n",
      "S1,S2 교집합 {'학습', '문제', '기계', '신경망'} --> 4\n",
      "\n",
      "S1-S2 similarity =  0.9582244629880743\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['기계', '학습', '신경망', '문제', '이용']\n",
      "[s2] ['인공', '신경망', '교사', '신호', '문제', '교사', '학습', '교사', '신호', '비', '교사', '학습']\n",
      "\n",
      "S1,S2 교집합 {'문제', '학습', '신경망'} --> 3\n",
      "\n",
      "S1-S2 similarity =  0.7327180100279169\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['기계', '학습', '신경망', '문제', '이용']\n",
      "[s2] ['교사', '학습', '비', '교사', '학습', '이용']\n",
      "\n",
      "S1,S2 교집합 {'이용', '학습'} --> 2\n",
      "\n",
      "S1-S2 similarity =  0.5880282075904122\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[s1] ['기계', '학습', '신경망', '문제', '이용']\n",
      "[s2] ['기계', '학습', '신경망', '문제', '이용']\n",
      "\n",
      "S1,S2 교집합 {'이용', '문제', '신경망', '기계', '학습'} --> 5\n",
      "\n",
      "S1-S2 similarity =  1.5533373363990297\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sent_textrank_graph = sent_graph(sents, textrank_sent_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 간 similarity가 0.3 보다 작은 경우에는 edge를 연결하지 않기로 했으므로\n",
    "1번째 문장과 3번쨰 문장의 유사도는 0이 되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.36454936 0.79210179 0.         0.95822446]\n",
      " [0.79210179 1.40850362 0.70148099 0.73271801]\n",
      " [0.         0.70148099 1.11622125 0.58802821]\n",
      " [0.95822446 0.73271801 0.58802821 1.55333734]]\n"
     ]
    }
   ],
   "source": [
    "print(sent_textrank_graph.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-4. 문장 그래프을 pagerank에 적용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PageRank\n",
    "\n",
    "$PR(u)=c*\\Sigma_{v∈B_{u}}\\frac{PR(v)}{N_{v}}+(1-c)$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$B_{u}$ 는 page $u$ 의 backlinks 의 출발점 마디이고, $v$ -> $u$로 연결이 있다. <br>\n",
    "$N_{v}$ 는 $v$가 가진 link 의 개수<br>\n",
    "$c$는 dampling factor 로 그래프의 다른 vertex로 이동할 확률, $1-c$는 새롭게 vertex에 유입될 확률 <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(x, df=0.85, max_iter=30, bias=None):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    x : scipy.sparse.csr_matrix\n",
    "        shape = (n vertex, n vertex)\n",
    "    df : float\n",
    "        Damping factor, 0 < df < 1\n",
    "    max_iter : int\n",
    "        Maximum number of iteration\n",
    "    bias : numpy.ndarray or None\n",
    "        If None, equal bias\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    R : numpy.ndarray\n",
    "        PageRank vector. shape = (n vertex, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    assert 0 < df < 1\n",
    "\n",
    "    # initialize\n",
    "    A = normalize(x, axis=0, norm='l1')\n",
    "    R = np.ones(A.shape[0]).reshape(-1,1)\n",
    "\n",
    "    # check bias\n",
    "    if bias is None:\n",
    "        bias = (1 - df) * np.ones(A.shape[0]).reshape(-1,1)\n",
    "    else:\n",
    "        bias = bias.reshape(-1,1)\n",
    "        bias = A.shape[0] * bias / bias.sum()\n",
    "        assert bias.shape[0] == A.shape[0]\n",
    "        bias = (1 - df) * bias\n",
    "\n",
    "    # iteration\n",
    "    for _ in range(max_iter):\n",
    "        R = df * (A * R) + bias\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine similarity와 textrank similarity를 비교한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_cosine_graph = sent_graph(sents, cosine_sent_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.        , 0.40006613, 0.36514837, 0.60246408],\n",
       "        [0.40006613, 1.        , 0.7768986 , 0.3380617 ],\n",
       "        [0.36514837, 0.7768986 , 1.        , 0.42426407],\n",
       "        [0.60246408, 0.3380617 , 0.42426407, 1.        ]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cosine_graph.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_textrank_graph = sent_graph(sents, textrank_sent_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.36454936, 0.79210179, 0.        , 0.95822446],\n",
       "        [0.79210179, 1.40850362, 0.70148099, 0.73271801],\n",
       "        [0.        , 0.70148099, 1.11622125, 0.58802821],\n",
       "        [0.95822446, 0.73271801, 0.58802821, 1.55333734]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_textrank_graph.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "damping_factor = 0.85\n",
    "max_iter=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97279733 1.01887586 1.03656275 0.97176406]\n"
     ]
    }
   ],
   "source": [
    "rank_cosine_keysent = pagerank(sent_cosine_graph, damping_factor, max_iter).reshape(-1)\n",
    "print(rank_cosine_keysent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95370662 1.10302224 0.79396838 1.14930277]\n"
     ]
    }
   ],
   "source": [
    "rank_textrank_keysent = pagerank(sent_textrank_graph, damping_factor, max_iter).reshape(-1)\n",
    "print(rank_textrank_keysent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 2 Sentence Index >> [2 1]\n",
      "\n",
      "< Cosine Similarity Result >\n",
      "rank [1.037] \n",
      "sent#2 명확한 해답이 있는 경우에는 교사 학습이, 데이터 클러스터링에는 비교사 학습이 이용된다\n",
      "\n",
      "rank [1.019] \n",
      "sent#1 인공신경망에는 교사 신호(정답)의 입력에 의해서 문제에 최적화되어 가는 교사 학습과 교사 신호를 필요로 하지 않는 비교사 학습이 있다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = 2\n",
    "\n",
    "idxs_cosine = np.argsort(-rank_cosine_keysent)[:top]\n",
    "print(\"TOP {} Sentence Index >> {}\\n\".format( top, idxs_cosine))\n",
    "\n",
    "print(\"< Cosine Similarity Result >\")\n",
    "for i in idxs_cosine:\n",
    "    print('rank [{:.4}] \\nsent#{} {}\\n'.format(rank_cosine_keysent[i], i, sents[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 2 Sentence Index >> [3 1]\n",
      "\n",
      "< TextRank Similarity Result >\n",
      "rank [1.149] \n",
      "sent#3 다른 기계학습과 같이 신경망은 일반적으로 규칙기반 프로그래밍으로 풀기 어려운 컴퓨터 비전 또는 음성 인식과 같은 다양한 범위의 문제를 푸는데 이용된다.\n",
      "\n",
      "rank [1.103] \n",
      "sent#1 인공신경망에는 교사 신호(정답)의 입력에 의해서 문제에 최적화되어 가는 교사 학습과 교사 신호를 필요로 하지 않는 비교사 학습이 있다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idxs_textrank = np.argsort(-rank_textrank_keysent)[:top] \n",
    "print(\"TOP {} Sentence Index >> {}\\n\".format( top, idxs_textrank))\n",
    "\n",
    "print(\"< TextRank Similarity Result >\")\n",
    "for i in idxs_textrank:\n",
    "    print('rank [{:.4}] \\nsent#{} {}\\n'.format(rank_textrank_keysent[i], i, sents[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "긴 문장을 선호하는 TextRank Similarity에 비해 Cosine Similarity 의 결과에 문장에 쓰인 단어가<br>\n",
    "적지만 동시에 등장한 단어가 많았기 때문에 짧은 문장의 rank 값이 높은 것을 확인할 수 있다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
